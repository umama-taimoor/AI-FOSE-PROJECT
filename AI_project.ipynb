{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "!pip install opencv-python\n",
    "!pip install ultralytics\n",
    "!pip install mediapipe\n",
    "!pip install --upgrade numpy\n",
    "!pip install --upgrade pandas tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a06f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Javascript, Image\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "from google.colab import files\n",
    "import mediapipe as mp\n",
    "\n",
    "# Constants\n",
    "OBJECT_COLOR = (0, 255, 0)\n",
    "FACE_COLOR = (0, 0, 255)\n",
    "HAND_COLOR = (255, 0, 0)\n",
    "CONF_THRESHOLD = 0.3\n",
    "KNOWN_DIMENSIONS = {\n",
    "    \"person\": 170, \"face\": 15, \"hand\": 18, \"cell phone\": 15, \"chair\": 45,\n",
    "    \"cup\": 8, \"bottle\": 25, \"car\": 450, \"keyboard\": 45,\n",
    "    \"laptop\": 35, \"mouse\": 10, \"book\": 25, \"tv\": 100\n",
    "}\n",
    "SENSOR_WIDTH = 3.68\n",
    "IMAGE_WIDTH = 640\n",
    "\n",
    "# Globals\n",
    "focalLength = 1000\n",
    "objectModel = YOLO('yolov8n.pt')\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "mpHands = mp.solutions.hands\n",
    "handsDetector = mpHands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mpDrawing = mp.solutions.drawing_utils\n",
    "\n",
    "def calculateDistance(objectClass, bboxWidth, bboxHeight, frameWidth):\n",
    "    knownDimension = KNOWN_DIMENSIONS.get(objectClass.lower())\n",
    "    if knownDimension is None:\n",
    "        bboxSize = max(bboxWidth, bboxHeight)\n",
    "        distance = (frameWidth * 100) / (bboxSize + 1e-6)\n",
    "        return distance, False\n",
    "    if objectClass.lower() in [\"face\", \"hand\"]:\n",
    "        distance = (knownDimension * focalLength) / (bboxWidth + 1e-6)\n",
    "    else:\n",
    "        distance = (knownDimension * focalLength) / (max(bboxWidth, bboxHeight) + 1e-6)\n",
    "    return distance, True\n",
    "\n",
    "def detectObjects(frame):\n",
    "    results = objectModel(frame, conf=CONF_THRESHOLD)\n",
    "    detections = []\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            bboxWidth = x2 - x1\n",
    "            bboxHeight = y2 - y1\n",
    "            conf = float(box.conf[0])\n",
    "            cls = int(box.cls[0])\n",
    "            className = result.names[cls]\n",
    "            if className.lower() == \"person\":\n",
    "                continue\n",
    "            distance, isCalculated = calculateDistance(className, bboxWidth, bboxHeight, frame.shape[1])\n",
    "            detections.append(\n",
    "            {\n",
    "                'bbox': (x1, y1, x2, y2),\n",
    "                'conf': conf,\n",
    "                'class': className,\n",
    "                'distance': distance,\n",
    "                'isCalculated': isCalculated,\n",
    "                'width': bboxWidth,\n",
    "                'height': bboxHeight\n",
    "            })\n",
    "    return detections\n",
    "\n",
    "def detectFaces(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    detections = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        distance, isCalculated = calculateDistance(\"face\", w, h, frame.shape[1])\n",
    "        detections.append(\n",
    "        {\n",
    "            'bbox': (x, y, x + w, y + h),\n",
    "            'distance': distance,\n",
    "            'isCalculated': isCalculated,\n",
    "            'width': w,\n",
    "            'height': h,\n",
    "            'class': 'face'\n",
    "        })\n",
    "    return detections\n",
    "\n",
    "def detectHands(frame):\n",
    "    rgbFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = handsDetector.process(rgbFrame)\n",
    "    detections = []\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLandmarks in results.multi_hand_landmarks:\n",
    "            landmarksArray = np.array([(lm.x * frame.shape[1], lm.y * frame.shape[0]) for lm in handLandmarks.landmark])\n",
    "            xMin, yMin = landmarksArray.min(axis=0).astype(int)\n",
    "            xMax, yMax = landmarksArray.max(axis=0).astype(int)\n",
    "            bboxWidth = xMax - xMin\n",
    "            bboxHeight = yMax - yMin\n",
    "            distance, isCalculated = calculateDistance(\"hand\", bboxWidth, bboxHeight, frame.shape[1])\n",
    "            detections.append(\n",
    "            {\n",
    "                'bbox': (xMin, yMin, xMax, yMax),\n",
    "                'distance': distance,\n",
    "                'isCalculated': isCalculated,\n",
    "                'width': bboxWidth,\n",
    "                'height': bboxHeight,\n",
    "                'class': 'hand',\n",
    "                'landmarks': handLandmarks\n",
    "            })\n",
    "    return detections\n",
    "\n",
    "def processFrame(frame):\n",
    "    resultFrame = frame.copy()\n",
    "    objects = detectObjects(frame)\n",
    "    faces = detectFaces(frame)\n",
    "    hands = detectHands(frame)\n",
    "\n",
    "    for obj in objects:\n",
    "        x1, y1, x2, y2 = obj['bbox']\n",
    "        cv2.rectangle(resultFrame, (x1, y1), (x2, y2), OBJECT_COLOR, 2)\n",
    "        distanceText = f\"{obj['distance']:.1f}cm\" if obj['isCalculated'] else f\"~{obj['distance']:.1f}cm\"\n",
    "        label = f\"{obj['class']}{obj['conf']:.2f}:{distanceText}\"\n",
    "        cv2.putText(resultFrame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, OBJECT_COLOR, 2)\n",
    "\n",
    "    for face in faces:\n",
    "        x1, y1, x2, y2 = face['bbox']\n",
    "        cv2.rectangle(resultFrame, (x1, y1), (x2, y2), FACE_COLOR, 2)\n",
    "        distanceText = f\"{face['distance']:.1f}cm\" if face['isCalculated'] else f\"~{face['distance']:.1f}cm\"\n",
    "        label = f\"Face: {distanceText}\"\n",
    "        cv2.putText(resultFrame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, FACE_COLOR, 2)\n",
    "\n",
    "    for hand in hands:\n",
    "        x1, y1, x2, y2 = hand['bbox']\n",
    "        cv2.rectangle(resultFrame, (x1, y1), (x2, y2), HAND_COLOR, 2)\n",
    "        distanceText = f\"{hand['distance']:.1f}cm\" if hand['isCalculated'] else f\"~{hand['distance']:.1f}cm\"\n",
    "        label = f\"Hand:{distanceText}\"\n",
    "        cv2.putText(resultFrame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, HAND_COLOR, 2)\n",
    "        if 'landmarks' in hand:\n",
    "            mpDrawing.draw_landmarks(resultFrame, hand['landmarks'], mpHands.HAND_CONNECTIONS,\n",
    "                                     mpDrawing.DrawingSpec(color=HAND_COLOR, thickness=2, circle_radius=2),\n",
    "                                     mpDrawing.DrawingSpec(color=HAND_COLOR, thickness=2, circle_radius=2))\n",
    "    return resultFrame\n",
    "\n",
    "def calibrateCamera(knownDistance, knownWidth, frameWidth):\n",
    "    global focalLength\n",
    "    focalLength = (knownWidth * frameWidth) / (knownDistance + 1e-6)\n",
    "    print(f\"Calibrated focal length: {focalLength:.2f} pixels\")\n",
    "\n",
    "def cv2Imshow(image):\n",
    "    _, encodedImage = cv2.imencode('.jpg', image)\n",
    "    display(Image(data=encodedImage.tobytes()))\n",
    "\n",
    "def runDetectorOnWebcam():\n",
    "    js = \"\"\"<your JavaScript code here>\"\"\"  # Skipped for brevity\n",
    "\n",
    "    try:\n",
    "        dummyFrame = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "        processFrame(dummyFrame)\n",
    "        print(\"Models loaded successfully!\")\n",
    "        print(\"Starting webcam capture. Press Ctrl+C to stop.\")\n",
    "\n",
    "        while True:\n",
    "            display(Javascript(js))\n",
    "            result = eval_js(\"captureWebcam()\")\n",
    "            if not result['success']:\n",
    "                print(f\"Error accessing webcam: {result.get('error', 'Unknown error')}\")\n",
    "                break\n",
    "            imageData = b64decode(result['image'])\n",
    "            imageArray = np.frombuffer(imageData, dtype=np.uint8)\n",
    "            frame = cv2.imdecode(imageArray, cv2.IMREAD_COLOR)\n",
    "            resultFrame = processFrame(frame)\n",
    "            cv2Imshow(resultFrame)\n",
    "            time.sleep(0.5)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nWebcam capture stopped\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def runDetectorOnImage(imagePath):\n",
    "    frame = cv2.imread(imagePath)\n",
    "    if frame is None:\n",
    "        print(f\"Error: Could not read image from {imagePath}\")\n",
    "        return\n",
    "    resultFrame = processFrame(frame)\n",
    "    print(f\"Detection results for {imagePath}:\")\n",
    "    cv2Imshow(resultFrame)\n",
    "\n",
    "def testWithSampleImage():\n",
    "    print(\"Please upload an image file:\")\n",
    "    uploaded = files.upload()\n",
    "    if uploaded:\n",
    "        imagePath = list(uploaded.keys())[0]\n",
    "        runDetectorOnImage(imagePath)\n",
    "    else:\n",
    "        print(\"No image uploaded.\")\n",
    "\n",
    "def main():\n",
    "    print(\"Enhanced Object, Face and Hand Detection System with Distance Estimation\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(\"1. Run with webcam (requires Colab)\")\n",
    "    print(\"2. Test with a sample image\")\n",
    "    print(\"3. Exit\")\n",
    "\n",
    "    while True:\n",
    "        choice = input(\"\\nEnter your choice (1-3): \")\n",
    "        if choice == '1':\n",
    "            try:\n",
    "                import ultralytics\n",
    "                import mediapipe\n",
    "            except ImportError:\n",
    "                print(\"Installing required packages...\")\n",
    "                !pip install ultralytics opencv-python-headless mediapipe\n",
    "            runDetectorOnWebcam()\n",
    "            break\n",
    "        elif choice == '2':\n",
    "            testWithSampleImage()\n",
    "            break\n",
    "        elif choice == '3':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice! Please enter 1, 2, or 3.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
